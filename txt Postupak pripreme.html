<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="hr" xml:lang="hr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Postupak pripreme podataka</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="txt Postupak pripreme_files/libs/clipboard/clipboard.min.js"></script>
<script src="txt Postupak pripreme_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="txt Postupak pripreme_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="txt Postupak pripreme_files/libs/quarto-html/popper.min.js"></script>
<script src="txt Postupak pripreme_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="txt Postupak pripreme_files/libs/quarto-html/anchor.min.js"></script>
<link href="txt Postupak pripreme_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="txt Postupak pripreme_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="txt Postupak pripreme_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="txt Postupak pripreme_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="txt Postupak pripreme_files/libs/bootstrap/bootstrap-813c323200a87c37e262811031999de4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul class="collapse">
  <li><a href="#uvod-u-pripremu-podataka" id="toc-uvod-u-pripremu-podataka" class="nav-link active" data-scroll-target="#uvod-u-pripremu-podataka">Uvod u pripremu podataka</a>
  <ul class="collapse">
  <li><a href="#tokenizacija" id="toc-tokenizacija" class="nav-link" data-scroll-target="#tokenizacija">Tokenizacija</a></li>
  <li><a href="#uklanjanje-stop-riječi" id="toc-uklanjanje-stop-riječi" class="nav-link" data-scroll-target="#uklanjanje-stop-riječi">Uklanjanje stop-riječi</a></li>
  <li><a href="#lematizacija-i-stemizacija" id="toc-lematizacija-i-stemizacija" class="nav-link" data-scroll-target="#lematizacija-i-stemizacija">Lematizacija i stemizacija</a></li>
  <li><a href="#izazovi-hrvatskog-jezika" id="toc-izazovi-hrvatskog-jezika" class="nav-link" data-scroll-target="#izazovi-hrvatskog-jezika">Izazovi hrvatskog jezika</a></li>
  <li><a href="#čišćenje-i-normalizacija" id="toc-čišćenje-i-normalizacija" class="nav-link" data-scroll-target="#čišćenje-i-normalizacija">Čišćenje i normalizacija</a></li>
  <li><a href="#zaključna-razmatranja" id="toc-zaključna-razmatranja" class="nav-link" data-scroll-target="#zaključna-razmatranja">Zaključna razmatranja</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="txt-Postupak-pripreme.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li><li><a href="txt Postupak pripreme.docx"><i class="bi bi-file-word"></i>MS Word</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Postupak pripreme podataka</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="uvod-u-pripremu-podataka" class="level1">
<h1>Uvod u pripremu podataka</h1>
<p>Zamislimo situaciju u kojoj istraživač masovne komunikacije želi analizirati više od pedeset tisuća komentara čitatelja objavljenih ispod članaka vodećih hrvatskih informativnih portala tijekom jedne izborne kampanje. Sirovi tekst koji prikuplja iz digitalnog okruženja predstavlja kaotičan niz znakova, interpunkcijskih oznaka, pogrešno napisanih riječi, emotikona i raznovrsnih tipografskih varijacija. Takav materijal u svom izvornom obliku nije pogodan za sustavnu analizu jer analitičke metode zahtijevaju određenu razinu strukturiranosti i konzistentnosti podataka. <strong>Priprema podataka</strong> stoga predstavlja temeljni korak koji prethodi svakoj računalno potpomognutoj analizi teksta, a njezina kvaliteta izravno određuje valjanost i pouzdanost konačnih rezultata istraživanja.</p>
<p>Proces pripreme podataka obuhvaća niz postupaka kojima se nestrukturirani tekst transformira u oblik prikladan za kvantitativnu obradu. Može se reći da ovaj postupak predstavlja svojevrsni most između sirovog jezičnog materijala i njegova numeričkog prikaza koji omogućuje primjenu statističkih i računalnih metoda. Valja napomenuti da odluke donesene u ovoj fazi imaju dalekosežne posljedice jer svako pojednostavljenje teksta nužno uključuje određeni gubitak informacija. Istraživač stoga mora pažljivo balansirati između potrebe za redukcijom složenosti i očuvanja semantički relevantnih svojstava teksta.</p>
<p>Nadalje, priprema podataka nije neutralan tehnički postupak već epistemološki čin koji odražava teorijske pretpostavke istraživača o prirodi jezika i komunikacije. Kada odlučujemo koje elemente teksta zadržati, a koje odbaciti, implicitno definiramo što smatramo značajnim za naše istraživačko pitanje. Upravo zato je od iznimne važnosti da istraživač razumije logiku svakoga koraka u procesu pripreme te da svoje odluke može argumentirano obrazložiti.</p>
<section id="tokenizacija" class="level2">
<h2 class="anchored" data-anchor-id="tokenizacija">Tokenizacija</h2>
<p>Prva i najtemeljnija operacija u pripremi tekstualnih podataka jest <strong>tokenizacija</strong>, postupak raščlanjivanja kontinuiranog niza teksta na diskretne jedinice koje nazivamo <strong>tokenima</strong>. Token predstavlja najmanju jedinicu analize, a ovisno o istraživačkom pitanju može predstavljati pojedinačnu riječ, n-gram, rečenicu ili čak odlomak. U kontekstu istraživanja masovne komunikacije najčešće se kao token koristi pojedinačna riječ budući da riječi predstavljaju temeljne nositelje značenja u jeziku.</p>
<p>Intuitivno se može činiti da je razdvajanje teksta na riječi trivijalan zadatak koji se svodi na prepoznavanje razmaka između riječi. Međutim, stvarna situacija znatno je složenija. Kada istraživač analizira komentare s društvenih mreža, susreće se s izrazima poput “ne-mogu-vjerovati” pisanima spojeno crticama, kraticama poput “dr.” ili “tj.” koje završavaju točkom koja nije kraj rečenice, emoticijama izraženima interpunkcijom poput “:)” ili “!!!” te nizom drugih graničnih slučajeva koji zahtijevaju jasna pravila razgraničenja.</p>
<p>Formalno gledano, tokenizacija se može definirati kao funkcija koja preslikava niz znakova <span class="math inline">\(S\)</span> u uređenu listu tokena <span class="math inline">\(T = (t_1, t_2, \ldots, t_n)\)</span>, pri čemu su tokeni najčešće razgraničeni razmacima i interpunkcijskim znakovima. Proces obično uključuje i dodatne transformacije poput pretvaranja svih znakova u mala slova čime se osigurava da riječi “Politika”, “politika” i “POLITIKA” budu prepoznate kao ista jedinica analize. Ova odluka o izjednačavanju velikih i malih slova može imati značajne posljedice za istraživanje jer se u hrvatskom jeziku velika početna slova koriste za označavanje vlastitih imena, početaka rečenica te u pojedinim stilskim konvencijama naslova.</p>
<p>S druge strane, vrsta tokena koju odabiremo izravno utječe na razinu analize i vrstu uvida koje možemo dobiti. Kada analiziramo tekst na razini pojedinačnih riječi, zadržavamo visoku rezoluciju ali gubimo informacije o odnosima između riječi. Upravo zato se u praksi često koriste <strong>n-grami</strong>, odnosno sekvence od <span class="math inline">\(n\)</span> uzastopnih tokena. <strong>Bigram</strong> čini par susjednih riječi, dok <strong>trigram</strong> obuhvaća tri uzastopne riječi. Primjerice, iz rečenice “Vlada najavljuje nove mjere” možemo ekstrahirati bigrame “Vlada najavljuje”, “najavljuje nove” i “nove mjere”. Takav pristup omogućuje hvatanje kolokacija i frazema koji nose značenje različito od zbroja značenja pojedinačnih riječi, što je osobito važno u analizi političkog diskursa gdje izrazi poput “nacionalni interes”, “javni dug” ili “socijalna pravda” funkcioniraju kao stabilne semantičke jedinice.</p>
<p>Za istraživače usmjerene na analizu uokvirivanja ili narativnih struktura može biti korisno provesti tokenizaciju na razini rečenica ili odlomaka. Takva makro-tokenizacija omogućuje analizu teksta na diskursnoj razini te olakšava praćenje razvoja argumentacije ili promjena tema unutar pojedinog dokumenta. Odluka o razini tokenizacije stoga nije tehnička već teorijska jer implicira određeno razumijevanje toga gdje u tekstu treba tražiti značenje.</p>
<p>Tablica 1 ilustrira rezultat tokenizacije kratkog ulomka iz hipotetskog novinarskog teksta.</p>
<table class="caption-top table">
<caption>Primjer tokenizacije novinarskog teksta</caption>
<thead>
<tr class="header">
<th style="text-align: center;">Redni broj</th>
<th style="text-align: left;">Token</th>
<th style="text-align: left;">Vrsta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: left;">predsjednik</td>
<td style="text-align: left;">imenica</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: left;">vlade</td>
<td style="text-align: left;">imenica</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: left;">najavio</td>
<td style="text-align: left;">glagol</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: left;">je</td>
<td style="text-align: left;">pomoćni glagol</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: left;">nove</td>
<td style="text-align: left;">pridjev</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: left;">gospodarske</td>
<td style="text-align: left;">pridjev</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: left;">mjere</td>
<td style="text-align: left;">imenica</td>
</tr>
</tbody>
</table>
<p>Vidimo da tokenizacija razlaže kontinuirani tekst na diskretne jedinice koje potom možemo brojiti, uspoređivati i statistički obrađivati. Ovaj postupak predstavlja konceptualni temelj za sve daljnje korake u pripremi podataka jer svaka naknadna transformacija operira nad tokenima kao temeljnim jedinicama analize.</p>
</section>
<section id="uklanjanje-stop-riječi" class="level2">
<h2 class="anchored" data-anchor-id="uklanjanje-stop-riječi">Uklanjanje stop-riječi</h2>
<p>Nakon što je tekst raščlanjen na tokene, uobičajeni sljedeći korak predstavlja <strong>filtriranje stop-riječi</strong>. Pod stop-riječima podrazumijevamo najčešće riječi u jeziku koje imaju pretežno gramatičku funkciju, a nose malo semantičkog sadržaja relevantnog za većinu analitičkih zadataka. U hrvatskom jeziku to uključuje riječi poput “i”, “je”, “u”, “da”, “se”, “na”, “za”, “biti” te brojne druge veznice, prijedloge, zamjenice i pomoćne glagole.</p>
<p>Intuicija koja stoji iza uklanjanja stop-riječi proizlazi iz jednostavne opservacije da su takve riječi ravnomjerno raspoređene kroz sve tekstove neovisno o njihovoj temi ili sadržaju. Kada istraživač želi identificirati ključne teme u korpusu novinskih članaka, činjenica da se riječ “je” pojavljuje stotine puta u svakom članku ne nosi nikakvu diskriminacijsku vrijednost. Naprotiv, takve visokofrekventne riječi mogu zamagliti obrasce koji su stvarno relevantni za razumijevanje sadržaja. Uklanjanje stop-riječi stoga služi povećanju omjera signala i šuma u podacima.</p>
<p>Postupak filtriranja stop-riječi konceptualno je jednostavan te uključuje usporedbu svakoga tokena sa zadanom listom stop-riječi i zadržavanje samo onih tokena koji se na listi ne nalaze. Međutim, odluka o tome koje riječi uključiti u listu stop-riječi daleko je od jednoznačne. Različite preddefinirane liste sadrže različit broj i izbor riječi, a za hrvatski jezik situacija je dodatno komplicirana relativnom oskudnošću standardiziranih resursa. Istraživači često kombiniraju dostupne liste s prilagođenim dodacima specifičnima za kontekst istraživanja.</p>
<p>Valja posebno istaknuti da je odluka o uklanjanju stop-riječi izrazito ovisna o kontekstu istraživanja. Postoje situacije u kojima gramatičke riječi nose značajnu informaciju. Primjerice, u analizi političkog diskursa uporaba zamjenica “mi” nasuprot “oni” može biti ključan indikator konstrukcije grupnog identiteta i retorike podjela. Slično tome, u analizi emocionalnog tona teksta negacije poput “ne” ili “nije” fundamentalno mijenjaju značenje rečenice i njihovo uklanjanje bi rezultiralo potpuno pogrešnom interpretacijom sentimenata. Upravo zato se preporučuje da istraživač pomno razmotri implikacije uklanjanja stop-riječi s obzirom na specifičnosti svoga istraživačkog pitanja.</p>
<p>Posljedično tome, mnogi istraživači pristupaju izradi <strong>prilagođenih lista stop-riječi</strong> koje odgovaraju specifičnostima njihova korpusa i analitičkih ciljeva. Postupak obično započinje preliminarnom analizom frekvencije riječi u korpusu kako bi se identificirale visokofrekventne riječi bez diskriminacijske vrijednosti. Te se riječi potom kritički evaluiraju u kontekstu istraživačkog pitanja te se donosi odluka o njihovu uključivanju u listu. Takav iterativni pristup omogućuje finiju kalibraciju između redukcije šuma i očuvanja relevantnih informacija.</p>
</section>
<section id="lematizacija-i-stemizacija" class="level2">
<h2 class="anchored" data-anchor-id="lematizacija-i-stemizacija">Lematizacija i stemizacija</h2>
<p>Flektivna priroda hrvatskog jezika znači da ista riječ može poprimiti brojne oblike ovisno o gramatičkoj kategoriji u kojoj se javlja. Imenica “politika” tako se pojavljuje u oblicima “politike”, “politici”, “politiku”, “politikom”, dok glagol “vladati” varira kroz oblike “vlada”, “vladaju”, “vladao”, “vladala”, “vladali” i tako dalje. Za računalnu analizu ova morfološka raznolikost predstavlja izazov jer sustav bez dodatne obrade tretira svaki oblik kao zasebnu jedinicu, čime se umjetno povećava dimenzionalnost podataka i smanjuje mogućnost prepoznavanja obrazaca.</p>
<p><strong>Stemizacija</strong> i <strong>lematizacija</strong> dva su komplementarna pristupa rješavanju ovog problema, pri čemu oba teže svođenju različitih morfoloških varijanti riječi na zajednički korijen. Njihova temeljna logika je intuitivno jasna jer ako znamo da oblici “ekonomija”, “ekonomije”, “ekonomski” i “ekonomista” dijele zajedničku semantičku jezgru, ima smisla tretirati ih kao manifestacije iste temeljne konceptualne jedinice prilikom analize sadržaja.</p>
<p><strong>Stemizacija</strong> predstavlja heuristički pristup koji koristi skup pravila za uklanjanje sufiksa i prefiksa s riječi kako bi se dobio korijen ili <strong>stem</strong>. Algoritmi za stemizaciju operiraju isključivo nad oblikom riječi bez obzira na njezino značenje ili gramatičku funkciju u rečenici. Za engleski jezik najpoznatiji je Porterov algoritam koji primjenjuje slijed pravila poput uklanjanja nastavaka “-ing”, “-ed”, “-ness” i sličnih. Rezultat stemizacije nije nužno valjana riječ u jeziku već apstraktni korijen koji služi kao oznaka klase morfološki srodnih riječi.</p>
<p>S druge strane, <strong>lematizacija</strong> predstavlja lingvistički sofisticiraniji pristup koji svodi riječi na njihov <strong>kanonski oblik</strong> ili <strong>lemu</strong>, odnosno oblik koji bi se pronašao kao natuknica u rječniku. Za imenice to je nominativ jednine, za glagole infinitiv, za pridjeve nominativ jednine muškog roda i tako dalje. Za razliku od stemizacije, lematizacija uzima u obzir kontekst u kojem se riječ javlja i njezinu gramatičku funkciju. Tako će riječ “bolje” biti ispravno svedena na lemu “dobar” kao komparativ pridjeva, dok bi stemizacija vjerojatno proizvela nevaljani korijen poput “bolj”.</p>
<p>Razliku između ova dva pristupa možemo ilustrirati konkretnim primjerom. Uzmimo rečenicu “Gospodarski stručnjaci procijenili su gospodarske pokazatelje.” Stemizacija bi vjerojatno proizvela korijene “gospodar”, “stručnjak”, “procijen”, “gospodar”, “pokazatelj”, pri čemu vidimo da su riječi “gospodarski” i “gospodarskim” svedene na isti stem iako predstavljaju različite oblike istog pridjeva. Lematizacija bi pak proizvela leme “gospodarski”, “stručnjak”, “procijeniti”, “gospodarski”, “pokazatelj”, zadržavajući semantičku preciznost i proizvodeći isključivo valjane riječi hrvatskog jezika.</p>
<p>Odluka između stemizacije i lematizacije ovisi o specifičnostima istraživačkog pitanja i dostupnim resursima. Stemizacija je računalno učinkovitija i ne zahtijeva opsežne lingvističke resurse, što je čini praktičnom za brzu obradu velikih korpusa. Međutim, njezina agresivnost može rezultirati gubitkom semantičkih distinkcija ili, suprotno, neuspjehom u prepoznavanju morfološki nepravilnih oblika. Lematizacija pruža veću preciznost i zadržava semantičku koherentnost, ali zahtijeva sofisticirane lingvističke alate uključujući leksičke baze podataka i sustave za označavanje vrsta riječi. Za hrvatski jezik dostupnost takvih resursa predstavlja značajno ograničenje o čemu će biti riječi u nastavku.</p>
</section>
<section id="izazovi-hrvatskog-jezika" class="level2">
<h2 class="anchored" data-anchor-id="izazovi-hrvatskog-jezika">Izazovi hrvatskog jezika</h2>
<p>Primjena metoda računalne analize teksta na hrvatski jezik suočava se s nizom specifičnih izazova koji proizlaze iz lingvističkih karakteristika hrvatskog i relativne oskudnosti dostupnih jezičnih resursa. Dok su alati i metode razvijene pretežno za engleski jezik dostigli visoku razinu sofisticiranosti, njihova prilagodba morfološki bogatijim i resursno siromašnijim jezicima poput hrvatskog ostaje aktivan istraživački problem.</p>
<p><strong>Morfološka složenost</strong> hrvatskog jezika predstavlja fundamentalni izazov. Hrvatski pripada skupini slavenskih jezika s bogatom flektivnom morfologijom, što znači da imenice, pridjevi i zamjenice poznaju sedam padeža u jednini i množini, dok glagoli variraju prema licu, broju, vremenu, načinu i vidu. Posljedica toga je izrazito visok broj različitih oblika koje ista leksička jedinica može poprimiti. Procjenjuje se da prosječna hrvatska imenica ima četrnaest različitih morfoloških realizacija, dok glagoli mogu imati i preko stotinu oblika kada se uključe svi aspekti konjugacije. Ova morfološka raznolikost drastično povećava dimenzionalnost podataka i otežava prepoznavanje obrazaca.</p>
<p>Nadalje, relativno <strong>slobodan redoslijed riječi</strong> u hrvatskom predstavlja dodatnu komplikaciju za metode koje se oslanjaju na sekvencijalne obrasce poput analize n-grama. Dok u engleskom jeziku pozicija riječi unutar rečenice ima snažnu gramatičku funkciju, u hrvatskom se ista informacija kodira morfološkim nastavcima, a redoslijed riječi služi pretežno pragmatičkim i stilskim funkcijama. To znači da ista propozicija može biti izražena na više sintaktički različitih načina, što komplicira usporedbu tekstova i identifikaciju obrazaca.</p>
<p><strong>Nedostatak lingvističkih resursa</strong> za hrvatski jezik predstavlja praktičnu prepreku implementaciji sofisticiranih metoda analize. Dok za engleski jezik postoje opsežne leksičke baze poput WordNeta, validirani rječnici sentimenata s desecima tisuća označenih riječi te napredni sustavi za morfološku analizu, za hrvatski su takvi resursi znatno oskudniji. Hrvatski WordNet postoji, ali je manjeg opsega od engleskog originala. Rječnici sentimenata za hrvatski razvijaju se u akademskim projektima, no njihova pokrivenost i validacija variraju. Sustavi za lematizaciju hrvatskog teksta postoje, ali njihova preciznost ne doseže razinu dostupnu za engleski.</p>
<p>Problem <strong>višeznačnosti</strong> dodatno komplicira analizu hrvatskog teksta. Mnoge hrvatske riječi imaju višestruka značenja koja ovise o kontekstu, a razlikovanje tih značenja zahtijeva sofisticirane metode dezambiguacije. Primjerice, riječ “vlast” može se odnositi na političku vlast, vlast kao moć ili pak kao dio složenica poput “sudska vlast”. Slično tome, riječ “list” može označavati dio biljke, novine ili pak list papira. Bez kontekstualnog razumijevanja automatski sustavi često pogrešno interpretiraju takve riječi.</p>
<p>Specifičnosti <strong>digitalnog registra</strong> hrvatskog jezika dodatno usložnjavaju analizu tekstova s društvenih mreža i komentara na portalima. Korisnici često koriste nestandardne oblike pisanja uključujući ispuštanje dijakritičkih znakova, uporabu engleskih riječi i fraza, regionalizme i žargonizme te razne oblike kreativnog pravopisa. Tekst poput “neznam sta bi reko, bas mi je bed” uključuje više odstupanja od standardnog jezika koja algoritmi pripremljeni za standardni hrvatski neće ispravno obraditi.</p>
<p>Usprkos ovim izazovima, razvoj resursa za hrvatski jezik napreduje. Akademski projekti razvijaju i validiraju nove resurse, a napredak u metodama prijenosa učenja s bogatijih jezika otvara nove mogućnosti. Za istraživača masovne komunikacije ključno je da bude svjestan ovih ograničenja te da ih uzme u obzir prilikom interpretacije rezultata i procjene pouzdanosti svojih zaključaka.</p>
</section>
<section id="čišćenje-i-normalizacija" class="level2">
<h2 class="anchored" data-anchor-id="čišćenje-i-normalizacija">Čišćenje i normalizacija</h2>
<p>Sirovi tekst prikupljen iz digitalnih izvora gotovo uvijek sadrži elemente koji nisu relevantni za sadržajnu analizu, a mogu ometati rad analitičkih alata ili iskriviti rezultate. <strong>Čišćenje teksta</strong> obuhvaća skup postupaka kojima se uklanjaju takvi neželjeni elementi i standardizira format podataka. Premda se može činiti tehničkim i rutinskim, ovaj korak zahtijeva pažljivo razmatranje jer svaka odluka o uklanjanju ili transformaciji utječe na konačnu analizu.</p>
<p><strong>Uklanjanje interpunkcije</strong> jedan je od najčešćih koraka čišćenja. Točke, zarezi, upitnici i drugi interpunkcijski znakovi obično ne nose semantičku informaciju relevantnu za analizu sadržaja te se rutinski uklanjaju. Međutim, postoje konteksti u kojima interpunkcija može biti značajna, primjerice u analizi emocionalnog intenziteta gdje višestruki uskličnici ili upitnici mogu signalizirati pojačanu emocionalnu angažiranost autora. Slično tome, u analizi stila pisanja interpunkcija može biti relevantan indikator. Istraživač stoga mora procijeniti relevantnost interpunkcije za svoje specifično istraživačko pitanje.</p>
<p><strong>Uklanjanje brojeva</strong> još je jedan uobičajeni postupak čišćenja. Numeričke vrijednosti rijetko su relevantne za tematsku analizu teksta i njihovo zadržavanje može komplicirati daljnju obradu. S druge strane, u određenim kontekstima brojevi mogu nositi značajnu informaciju. U analizi ekonomskog diskursa reference na postotke, iznose ili datume mogu biti ključne za razumijevanje argumentacije. Ponovno, odluka ovisi o specifičnostima istraživanja.</p>
<p><strong>Normalizacija razmaka</strong> podrazumijeva ujednačavanje razmaka između riječi, uklanjanje višestrukih uzastopnih razmaka te standardizaciju drugih oblika praznog prostora poput tabulatora ili prijeloma redaka. Ovaj korak osigurava konzistentnost formata i olakšava naknadnu obradu.</p>
<p>Tekstovi prikupljeni s interneta često sadrže <strong>HTML oznake, URL adrese i posebne znakove</strong> koji su relevantni za prikaz teksta u pregledniku, ali nemaju sadržajnu vrijednost. Uklanjanje takvih elemenata dio je standardnog protokola čišćenja. Posebnu pažnju zahtijevaju <strong>emotikoni i emojiji</strong> koji su sve prisutniji u tekstovima digitalnih medija. Iako nemaju leksičko značenje u tradicionalnom smislu, emojiji često nose značajnu emocionalnu informaciju i mogu biti relevantni za određene tipove analize poput analize sentimenata.</p>
<p><strong>Normalizacija kodiranja znakova</strong> tehnički je aspekt koji može uzrokovati značajne probleme ako se previdi. Tekstovi prikupljeni iz različitih izvora mogu koristiti različite standarde kodiranja znakova, što može rezultirati pogrešnim prikazom dijakritičkih znakova tipičnih za hrvatski jezik poput č, ć, đ, š i ž. Ujednačavanje kodiranja na standardni UTF-8 format osigurava ispravnu obradu svih znakova.</p>
<p><strong>Normalizacija dijakritika</strong> specifičan je izazov za hrvatski jezik. Korisnici digitalnih medija često ispuštaju dijakritičke znakove pišući “zasto” umjesto “zašto” ili “covjek” umjesto “čovjek”. Istraživač može odlučiti normalizirati takve oblike na standardnu ortografiju ili pak zadržati nestandardne oblike kao indikator registra ili sociolingvističkih karakteristika autora. Prva opcija pojednostavljuje analizu dok druga zadržava potencijalno relevantnu informaciju.</p>
<p>Postupak čišćenja obično se primjenjuje <strong>prije tokenizacije</strong> kako bi se osiguralo da neželjeni elementi ne utječu na raščlambu teksta na tokene. Međutim, redoslijed koraka može varirati ovisno o specifičnim zahtjevima analize. Ključno je da istraživač dokumentira sve korake čišćenja i normalizacije koje je primijenio kako bi osigurao transparentnost i ponovljivost istraživanja.</p>
<p>Uzevši sve navedeno u obzir, postupak pripreme podataka može se konceptualizirati kao serija transformacija koje sirovi tekst prevode u strukturirani oblik spreman za analizu. Svaki korak uključuje implicitne i eksplicitne odluke o tome što je relevantno za istraživanje, a što predstavlja šum koji treba ukloniti. Kvaliteta pripreme podataka izravno utječe na valjanost rezultata, a transparentnost u dokumentiranju primijenjenih postupaka nužan je preduvjet znanstvene ponovljivosti.</p>
<p>Tablica 2 prikazuje pregled koraka pripreme podataka i njihovih implikacija za analizu.</p>
<table class="caption-top table">
<caption>Pregled koraka pripreme podataka i njihovih implikacija</caption>
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Korak</th>
<th style="text-align: left;">Svrha</th>
<th style="text-align: left;">Potencijalni gubitak informacija</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Tokenizacija</td>
<td style="text-align: left;">Raščlamba teksta na analitičke jedinice</td>
<td style="text-align: left;">Gubitak informacija o sekvencijalnim odnosima</td>
</tr>
<tr class="even">
<td style="text-align: left;">Uklanjanje stop-riječi</td>
<td style="text-align: left;">Redukcija šuma i dimenzionalnosti</td>
<td style="text-align: left;">Gubitak gramatičkih i pragmatičkih signala</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Lematizacija/stemizacija</td>
<td style="text-align: left;">Svođenje na korijenske oblike</td>
<td style="text-align: left;">Gubitak morfoloških distinkcija</td>
</tr>
<tr class="even">
<td style="text-align: left;">Čišćenje i normalizacija</td>
<td style="text-align: left;">Standardizacija formata</td>
<td style="text-align: left;">Gubitak stilističkih i registarskih signala</td>
</tr>
</tbody>
</table>
</section>
<section id="zaključna-razmatranja" class="level2">
<h2 class="anchored" data-anchor-id="zaključna-razmatranja">Zaključna razmatranja</h2>
<p>Valja zaključiti da je priprema podataka istovremeno tehnički i interpretativni postupak. Tehnička dimenzija odnosi se na praktičnu primjenu algoritama i procedura transformacije teksta, dok se interpretativna dimenzija ogleda u nizu odluka koje istraživač donosi o tome što zadržati, a što ukloniti. Te odluke trebaju biti teorijski utemeljene i dosljedno primijenjene na cijeli korpus, a njihova dokumentacija sastavni je dio metodološke transparentnosti svakog ozbiljnog istraživanja digitalnih medija.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>