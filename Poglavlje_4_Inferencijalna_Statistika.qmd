---
title: "Inferencijalna statistika"
subtitle: "Poglavlje 4: Testiranje hipoteza u praksi"
author: "Metode istraživanja masovne komunikacije"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: true
    theme: cosmo
  pdf:
    documentclass: article
    geometry: margin=1in
    fontsize: 12pt
    number-sections: true
lang: hr
---

# Inferencijalna statistika {#sec-inferencijalna-statistika}

U prethodnom poglavlju postavili smo teorijske temelje statističkog zaključivanja: naučili smo o normalnoj distribuciji, centralnom graničnom teoremu i standardnoj pogrešci. Sada je vrijeme da te apstraktne koncepte primijenimo u praksi. Kada istraživač masovne komunikacije provede eksperiment ili anketu, krajnji cilj nije samo opisati što se dogodilo u tom konkretnom uzorku, već izvesti zaključke o široj populaciji. Postoji li veza između izloženosti političkim vijestima i političkog znanja? Povećava li senzacionalni naslov broj klikova? Razlikuje se li kredibilitet tradicionalnih medija od kredibiliteta društvenih mreža? Na sva ova pitanja želimo odgovoriti na način koji nadilazi konkretne podatke koje smo prikupili. U ovom poglavlju fokusirat ćemo se na logiku i mehaniku **testiranja hipoteza** – sistematičan pristup donošenju statističkih odluka. Započet ćemo s logikom nulte hipoteze i objašnjenjem zašto se statistički test ponaša više kao suđenje nego kao znanstveno istraživanje. Zatim ćemo detaljno razmotriti p-vrijednost, najvažniji (i često najpogrešnije shvaćen) broj u inferencijalnoj statistici. Konačno, razmotriti ćemo vrste pogrešaka koje možemo napraviti prilikom testiranja i kako ih držati pod kontrolom.

## Logika nulte hipoteze {#sec-logika-nulte-hipoteze}

Zamislimo da portal Index.hr tvrdi da njihovi članci prosječno generiraju 50 komentara. Istraživač koji istražuje angažman korisnika odluči provjeriti ovu tvrdnju, pa nasumično odabere 100 članaka i otkrije da je prosječan broj komentara 58, sa standardnom devijacijom od 25. Trebamo li zaključiti da Index.hr potcjenjuje svoj angažman, ili je razlika od 8 komentara jednostavno slučajno odstupanje koje može nastati zbog uzorkovanja? Ovo je tipična situacija za testiranje hipoteza.

### Istraživačka vs. statistička hipoteza {#sec-istrazivacka-vs-statisticka}

Prije nego što možemo testirati bilo što, moramo jasno razlikovati dva tipa hipoteza. **Istraživačka hipoteza** (research hypothesis) je znanstvena tvrdnja o svijetu koja nas zanima. U našem primjeru, istraživačka hipoteza mogla bi biti "Index.hr podcjenjuje stvarni angažman svojih čitatelja" ili općenitije "angažman korisnika portala razlikuje se od službenih procjena". Ovo su tvrdnje o psihološkim ili komunikološkim konstruktima – o ponašanju ljudi, o učinku medijskog sadržaja, o prirodi komunikacijskih fenomena.

Međutim, istraživačke hipoteze su često nejasne i teško mjerljive. Što točno znači "podcjenjuje angažman"? Za koliko? U kojim situacijama? Da bismo mogli testirati hipotezu, moramo je prevesti u preciznu matematičku tvrdnju o podacima. Ovo je **statistička hipoteza**. U našem primjeru, statistička hipoteza mogla bi biti: "prava prosječna vrijednost komentara po članku ($\mu$) razlikuje se od 50", što matematički zapisujemo kao $\mu \neq 50$.

Ključno je razumjeti da statistički test testira statističku hipotezu, ne istraživačku. Ako naša studija je loše dizajnirana – na primjer, ako smo slučajno odabrali samo kontroverzne članke koji privlače više komentara – možemo dobiti statistički značajan rezultat ($\mu \neq 50$), ali to neće reći ništa istinito o našoj istraživačkoj hipotezi. Veza između istraživačke i statističke hipoteze održava se kvalitetom istraživačkog dizajna, ne statističkom analizom.

### Nulta i alternativna hipoteza {#sec-nulta-alternativna}

Ovdje dolazimo do nečega što zbunjuje većinu studenata: kada započinjemo statistički test, ne krećemo od hipoteze u koju vjerujemo. Umjesto toga, konstruiramo **nultu hipotezu** ($H_0$, čita se "ha nula") koja predstavlja ono što **ne** želimo biti istina, i zatim pokušavamo pokazati da je ona lažna. U našem Index.hr primjeru:

$$H_0: \mu = 50$$ {#eq-null-hypothesis}

Nulta hipoteza tvrdi da je Index.hr u pravu – prosječan broj komentara doista jest 50. **Alternativna hipoteza** ($H_1$ ili $H_A$) predstavlja ono što sumnjamo da je istina:

$$H_1: \mu \neq 50$$ {#eq-alternative-hypothesis}

Cilj statističkog testa nije pokazati da je alternativna hipoteza istinita, već pokazati da je nulta hipoteza lažna. Ovo je kontraintuitivno, ali postoji dobar razlog za ovakav pristup.

### Analogija sa suđenjem {#sec-analogija-sudenje}

Najbolji način da razumijemo logiku testiranja hipoteza jest analogija sa kaznenim suđenjem. **Nulta hipoteza je optuženik**, istraživač je tužitelj, a statistički test je sudac. Kao i u kaznenom suđenju, postoji **presumpcija nevinosti**: nulta hipoteza smatra se istinitom sve dok vi, istraživač, ne možete dokazati "izvan razumne sumnje" da je lažna. Vi slobodno možete dizajnirati svoj eksperiment kako želite (unutar razumnih granica), i vaš cilj je maksimizirati šansu da će podaci dovesti do "osude" – do odbacivanja nulte hipoteze.

No, pravila igre dizajnirana su da štite nultu hipotezu. Konkretno, pravila osiguravaju da ako je nulta hipoteza zapravo istinita, šansa za lažnu osudu je garantirano niska (obično ispod 5%). Ovo je važno jer nulta hipoteza ne dobiva odvjetnika. Budući da vi, istraživač, očajnički pokušavate dokazati da je lažna, netko mora štititi nultu hipotezu od nepravde.

Kao što engleski pravnik William Blackstone slavno reče: "Bolje je da deset krivaca pobjegne nego da jedan nevin pati." Statistički test slijedi istu filozofiju: daleko je važnije zaštititi istinitu nultu hipotezu od pogrešnog odbacivanja nego osigurati da svaku lažnu nultu hipotezu uspješno odbacimo. Ova asimetrija je fundamentalna za cijeli pristup.

### Konstrukcija testa: testna statistika {#sec-testna-statistika}

Da bismo mogli provesti test, trebamo **testnu statistiku** – broj koji računamo iz podataka i koji nam pomaže razlikovati između nulte i alternativne hipoteze. Za naš Index.hr primjer, prirodan izbor je prosječan broj komentara u našem uzorku, $\bar{X}$. Opazili smo $\bar{X} = 58$ komentara.

Međutim, sama po sebi ova brojka ne govori nam puno. Moramo znati kako se ta statistika ponaša **ako je nulta hipoteza istinita**. Drugim riječima, ako Index.hr doista ima prosjek od 50 komentara, kakve vrijednosti $\bar{X}$ bismo očekivali vidjeti u uzorku od 100 članaka? Centralni granični teorem nam daje odgovor: uzorkovna distribucija prosjeka bit će približno normalna sa sredinom $\mu = 50$ i standardnom pogreškom:

$$\text{SE} = \frac{\sigma}{\sqrt{N}} = \frac{25}{\sqrt{100}} = 2.5$$

Prema nultoj hipotezi, očekujemo da će $\bar{X}$ biti negdje oko 50, s tipičnim odstupanjem od 2.5 komentara. Naša opažena vrijednost od 58 je $(58 - 50) / 2.5 = 3.2$ standardne pogreške iznad očekivane vrijednosti. Je li to dovoljno ekstremno da odbacimo nultu hipotezu?

### Kritična regija i razina značajnosti {#sec-kriticna-regija}

Da bismo odgovorili na ovo pitanje, moramo definirati **kritičnu regiju** – skup vrijednosti testne statistike koji bi nas naveo na odbacivanje nulte hipoteze. Kako određujemo tu regiju? Koristimo **razinu značajnosti** $\alpha$ (alfa), koja predstavlja maksimalnu stopu pogreške tipa I koju smo spremni tolerirati.

Konvencija u znanosti je obično $\alpha = 0.05$, što znači da smo spremni prihvatiti 5% šanse da ćemo pogrešno odbaciti istinitu nultu hipotezu. Budući da je naša alternativna hipoteza dvosmjerna ($\mu \neq 50$), kritična regija pokriva oba repa distribucije – 2.5% na svakoj strani. Za normalnu distribuciju, to odgovara vrijednostima više od 1.96 standardnih pogrešaka od sredine.

```{r}
#| label: fig-critical-region
#| echo: true
#| eval: false
#| fig-cap: "Kritična regija za dvosmjerni test"

# Parametri pod nultom hipotezom
mu0 <- 50
se <- 2.5
n <- 100

# Opseg za prikaz
x <- seq(mu0 - 4*se, mu0 + 4*se, length = 200)
y <- dnorm(x, mean = mu0, sd = se)

# Crtanje distribucije
plot(x, y, type = "l", lwd = 2,
     main = "Uzorkovna distribucija prosjeka pod H0",
     xlab = "Prosječan broj komentara",
     ylab = "Gustoća",
     las = 1)

# Kritične vrijednosti (α = 0.05, dvosmjerno)
crit_lower <- mu0 - 1.96 * se
crit_upper <- mu0 + 1.96 * se

# Senčanje kritičnih regija
x_lower <- seq(mu0 - 4*se, crit_lower, length = 100)
polygon(c(x_lower, rev(x_lower)),
        c(dnorm(x_lower, mu0, se), rep(0, 100)),
        col = rgb(1, 0, 0, 0.3), border = NA)

x_upper <- seq(crit_upper, mu0 + 4*se, length = 100)
polygon(c(x_upper, rev(x_upper)),
        c(dnorm(x_upper, mu0, se), rep(0, 100)),
        col = rgb(1, 0, 0, 0.3), border = NA)

# Opažena vrijednost
abline(v = 58, col = "blue", lwd = 2, lty = 2)
text(58, max(y)*0.7, "Opaženo:\n58", col = "blue")

# Kritične vrijednosti
abline(v = c(crit_lower, crit_upper), lty = 3)
text(crit_lower, max(y)*0.9, sprintf("%.1f", crit_lower), cex = 0.8)
text(crit_upper, max(y)*0.9, sprintf("%.1f", crit_upper), cex = 0.8)
```

Naša opažena vrijednost od 58 komentara pada u kritičnu regiju (58 > 55.1), stoga **odbacujemo nultu hipotezu**. Zaključujemo da imamo statističke dokaze da prosječan broj komentara nije 50.

### Jednosmjerni vs. dvosmjerni testovi {#sec-jednosmjerni-dvosmjerni}

U našem primjeru koristili smo **dvosmjerni test** jer nas je zanimalo bilo kakvo odstupanje od 50 – bilo prema gore ili prema dolje. Alternativna hipoteza bila je $H_1: \mu \neq 50$. Međutim, ponekad imamo jasnu pretpostavku o smjeru razlike. Na primjer, ako Index.hr tvrdi da njihov novi format povećava angažman, možda nas zanima samo je li prosječan broj komentara **veći** od prethodnih 50. U tom slučaju koristili bismo **jednosmjerni test**:

$$H_0: \mu \leq 50$$
$$H_1: \mu > 50$$

Za jednosmjerni test s $\alpha = 0.05$, sva kritična regija od 5% nalazi se u jednom repu distribucije. Kritična vrijednost tada je 1.645 standardnih pogrešaka (umjesto 1.96), što znači da je lakše postići značajnost ako smo u pravu o smjeru efekta. Međutim, ako se efekt pokaže u suprotnom smjeru, ne možemo odbaciti nultu hipotezu neovisno o tome koliko je efekt velik.

::: {.callout-warning}
## Oprez s jednosmjernim testovima

Jednosmjerni testovi trebaju biti opravdani jakom teorijskom ili praktičnom osnovom prije prikupljanja podataka. Odlučivanje o smjeru testa nakon što ste vidjeli podatke je neprihvatljivo – to je oblik "p-hackinga" koji inflira stopu pogreške tipa I.
:::

## P-vrijednost i statistička značajnost {#sec-p-vrijednost}

Pristup koji smo do sada opisali donosi binarnu odluku: ili odbacujemo nultu hipotezu ili je zadržavamo. Međutim, ovaj pristup ne pravi nikakvu razliku između rezultata koji su "jedva značajni" (npr. $\bar{X} = 55.2$) i onih koji su "vrlo značajni" ($\bar{X} = 68$). Obje situacije vode do odbacivanja nulte hipoteze ako je $\alpha = 0.05$, ali intuitivno osjećamo da druga pruža jače dokaze. Ovdje na scenu stupa **p-vrijednost**.

### Definicija p-vrijednosti {#sec-definicija-p}

P-vrijednost može se definirati na dva komplementarna načina. Prvi način (Neymanovski) glasi:

> P-vrijednost je **najmanji nivo značajnosti $\alpha$** koji biste morali biti spremni tolerirati da biste mogli odbaciti nultu hipotezu.

Za naš Index.hr primjer s opaženim prosjekom od 58 komentara, recimo da je p-vrijednost 0.001. To znači: da bi smo odbacili nultu hipotezu na temelju ovih podataka, morali bismo biti spremni tolerirati stopu pogreške tipa I od najmanje 0.1%. Ako smo spremni tolerirati 1% (ili bilo što veće), onda možemo odbaciti nultu hipotezu. Ako nismo spremni tolerirati čak ni 0.1% stopu pogreške, moramo zadržati nultu hipotezu.

Drugi način definiranja p-vrijednosti (Fisherov) je:

> P-vrijednost je **vjerojatnost dobivanja rezultata jednako ili više ekstremnih** od onih koje smo opazili, pod pretpostavkom da je nulta hipoteza istinita.

Za naš primjer: ako je prosječan broj komentara zaista 50, kolika je vjerojatnost da bismo u uzorku od 100 članaka dobili prosjek od 58 ili više (ili 42 ili manje, za dvosmjerni test)? Ako je ta vjerojatnost vrlo mala (npr. 0.001), to sugerira da naši podaci nisu konzistentni s nultom hipotezom.

```{r}
#| label: fig-p-value-calculation
#| echo: true
#| eval: false

# Parametri
mu0 <- 50
sigma <- 25
n <- 100
x_obs <- 58

# Izračun z-score
se <- sigma / sqrt(n)
z <- (x_obs - mu0) / se
cat("Z-score:", round(z, 3), "\n")

# Izračun p-vrijednosti (dvosmjerno)
p_value <- 2 * (1 - pnorm(abs(z)))
cat("P-vrijednost:", format(p_value, scientific = FALSE, digits = 4), "\n")

# Interpretacija
if (p_value < 0.001) {
  cat("Rezultat: p < 0.001 - vrlo jaki dokazi protiv H0\n")
} else if (p_value < 0.01) {
  cat("Rezultat: p < 0.01 - jaki dokazi protiv H0\n")
} else if (p_value < 0.05) {
  cat("Rezultat: p < 0.05 - umjereni dokazi protiv H0\n")
} else {
  cat("Rezultat: p >= 0.05 - nedovoljno dokaza za odbacivanje H0\n")
}
```

### Interpretacija p-vrijednosti {#sec-interpretacija-p}

P-vrijednost je možda najpogrešnije shvaćen koncept u statistici. Evo što p-vrijednost **nije**:

::: {.callout-important}
## Što p-vrijednost NIJE

- **NIJE** vjerojatnost da je nulta hipoteza istinita
- **NIJE** vjerojatnost da su rezultati nastali slučajno
- **NIJE** vjerojatnost da ste napravili pogrešku odbacujući $H_0$
- **NIJE** mjera veličine efekta ili praktične važnosti

P-vrijednost od 0.001 **ne** znači "postoji 0.1% šanse da je H0 istinita". Frekventistički pristup statistici ne dopušta pripisivanje vjerojatnosti hipotezama – one su ili istinite ili nisu.
:::

Pravilne interpretacije uključuju:

- "Ako bi nulta hipoteza bila istinita, podaci kao naši ili ekstremiji javljali bi se u 0.1% slučajeva"
- "Trebali bismo biti spremni tolerirati stopu pogreške tipa I od najmanje 0.1% da bismo odbacili H0"
- "Podaci pružaju jake dokaze protiv nulte hipoteze"

### Konvencije izvještavanja {#sec-konvencije-izvjestavanja}

Postoje dva pristupa izvještavanju p-vrijednosti. Prvi je izvještavanje **točne p-vrijednosti**:

- "Prosječan broj komentara bio je značajno veći od 50, $t(99) = 3.20$, $p = 0.002$"

Prednost ovog pristupa je da dopušta čitatelju da sam odluči što smatra prihvatljivom stopom pogreške. Mana je što pruža istraživaču previše fleksibilnosti – postoji iskušenje da se razina značajnosti "prilagodi" nakon što se vide podaci.

Drugi pristup je korištenje **standardnih pragova**:

| Notacija | Značenje | Razina značajnosti |
|:---------|:---------|:------------------|
| $p > 0.05$ ili n.s. | Nije značajno | Zadržavamo $H_0$ |
| $p < 0.05$ (*) | Značajno na razini 5% | Odbacujemo $H_0$ |
| $p < 0.01$ (**) | Značajno na razini 1% | Odbacujemo $H_0$ |
| $p < 0.001$ (***) | Vrlo značajno | Odbacujemo $H_0$ |

: Standardne konvencije za izvještavanje p-vrijednosti {#tbl-p-value-conventions}

Ovaj pristup štiti od posteksperimentalnog prilagođavanja $\alpha$ razine, ali stvara umjetnu "granicu" između značajnog i ne-značajnog ($p = 0.049$ tretira se fundamentalno drugačije od $p = 0.051$).

### Statistička vs. praktična značajnost {#sec-statisticka-prakticna}

Ključno je razumjeti da "statistički značajan" ne znači "važan" ili "praktično relevantan". Ove dvije stvari su potpuno različite. **Statistička značajnost** ovisi o tri faktora:

1. Veličini efekta (koliko se razlikuje od nulte hipoteze)
2. Veličini uzorka
3. Varijabilnosti u podacima

S dovoljno velikim uzorkom, čak i minijaturni efekti postaju statistički značajni. Zamislimo da analiziramo milijun članaka i otkrijemo da prosječan broj komentara nije 50.0 već 50.2. P-vrijednost može biti $p < 0.001$, ali je razlika od 0.2 komentara praktično beznačajna.

**Praktična značajnost** se ocjenjuje kroz veličinu efekta i kontekst. Za Index.hr, razlika između 50 i 58 komentara može biti praktično važna jer predstavlja 16% povećanje angažmana. Međutim, razlika između 50.0 i 50.2 nije praktično važna neovisno o p-vrijednosti.

## Vrste pogrešaka {#sec-vrste-pogresaka}

Statistički testovi nisu savršeni. Čak i kada sve radimo ispravno, postoji mogućnost pogreške. Svijet je kaotičan, podaci su bučni, i ponekad jednostavno imamo lošu sreću. Razumijevanje vrsta pogrešaka koje možemo napraviti, i kako ih kontrolirati, ključno je za kompetentno korištenje statističkih testova.

### Pogreška tipa I (lažno pozitivan) {#sec-pogreska-tipa-I}

**Pogreška tipa I** nastaje kada odbacimo istinitu nultu hipotezu. U kontekstu našeg Index.hr primjera, to bi značilo zaključiti da prosječan broj komentara nije 50 kada zapravo jest. U kriminalnoj analogiji, to je osuda nevinog čovjeka. Ova pogreška je toliko ozbiljna da je cijeli sustav testiranja hipoteza dizajniran primarno da je kontrolira.

Vjerojatnost pogreške tipa I označava se s $\alpha$ i ona je **razina značajnosti** testa. Kada postavljamo $\alpha = 0.05$, eksplicitno kažemo: "Spreman sam prihvatiti da ću u 5% slučajeva pogrešno odbaciti istinitu nultu hipotezu." Ovo je razlog zašto su konvencionalni pragovi (0.05, 0.01, 0.001) tako važni – oni predstavljaju društveno dogovorene nivoe prihvatljivog rizika.

Valja napomenuti da je $\alpha$ razina koju **mi biramo** prije provedbe testa. Ona nije svojstvo podataka, već svojstvo našeg pristupa testiranju. Ako smo konzervativniji i želimo biti sigurniji prije odbacivanja $H_0$, možemo postaviti $\alpha = 0.01$ ili čak $\alpha = 0.001$. Međutim, ovo ima cijena – postat će nam teže odbaciti čak i lažnu nultu hipotezu.

### Pogreška tipa II (lažno negativan) {#sec-pogreska-tipa-II}

**Pogreška tipa II** nastaje kada zadržimo lažnu nultu hipotezu. To bi značilo zaključiti da prosječan broj komentara jest 50 kada zapravo nije. U kriminalnoj analogiji, to je oslobađanje krivca. Vjerojatnost ove pogreške označava se s $\beta$ (beta).

Za razliku od pogreške tipa I, ne možemo direktno postaviti $\beta$ na određenu vrijednost. Umjesto toga, $\beta$ ovisi o nekoliko faktora:

1. **Veličina stvarnog efekta**: Što je stvarni efekt veći, manje je vjerojatna pogreška tipa II
2. **Veličina uzorka**: Veći uzorak znači manju $\beta$
3. **Varijabilnost podataka**: Manja varijabilnost znači manju $\beta$
4. **Razina $\alpha$**: Stroža $\alpha$ (npr. 0.01 umjesto 0.05) povećava $\beta$

```{r}
#| label: fig-type-errors
#| echo: true
#| eval: false
#| fig-cap: "Ilustracija pogrešaka tipa I i II"

# Parametri
mu0 <- 50  # Nulta hipoteza
mu1 <- 55  # Stvarna populacijska sredina (nepoznata)
sigma <- 25
n <- 100
se <- sigma / sqrt(n)
alpha <- 0.05

# Kritična vrijednost za dvosmjerni test
crit_upper <- mu0 + qnorm(1 - alpha/2) * se

# Distribucije
x <- seq(40, 70, length = 200)
y_h0 <- dnorm(x, mean = mu0, sd = se)
y_h1 <- dnorm(x, mean = mu1, sd = se)

# Grafikon
plot(x, y_h0, type = "l", lwd = 2, col = "blue",
     main = "Pogreške tipa I i II",
     xlab = "Prosječan broj komentara",
     ylab = "Gustoća",
     ylim = c(0, max(c(y_h0, y_h1))),
     las = 1)
lines(x, y_h1, lwd = 2, col = "red")

# Pogreška tipa I (plava senčana područja)
x_type1 <- x[x >= crit_upper]
polygon(c(x_type1, rev(x_type1)),
        c(dnorm(x_type1, mu0, se), rep(0, length(x_type1))),
        col = rgb(0, 0, 1, 0.3), border = NA)

# Pogreška tipa II (crvena senčana područja)
x_type2 <- x[x < crit_upper]
polygon(c(x_type2, rev(x_type2)),
        c(dnorm(x_type2, mu1, se), rep(0, length(x_type2))),
        col = rgb(1, 0, 0, 0.3), border = NA)

# Legenda
abline(v = crit_upper, lty = 2)
legend("topright",
       legend = c("Distribucija pod H0", "Distribucija pod H1",
                  "Pogreška tipa I (α)", "Pogreška tipa II (β)"),
       col = c("blue", "red", rgb(0,0,1,0.3), rgb(1,0,0,0.3)),
       lwd = c(2, 2, 10, 10))
```

### Moć testa {#sec-moc-testa}

Komplementarno pojmu pogreške tipa II, **moć testa** definira se kao:

$$\text{Moć} = 1 - \beta$$

Moć je vjerojatnost da ćemo **ispravno odbaciti lažnu** nultu hipotezu. "Moćan" test je onaj koji ima veliku vjerojatnost detektirati efekt kada efekt doista postoji. Drugim riječima, moć je osjetljivost testa.

Moć testa ovisi o istim faktorima kao i $\beta$, ali u suprotnom smjeru:

- **Veći stvarni efekt** → veća moć
- **Veći uzorak** → veća moć
- **Manja varijabilnost** → veća moć
- **Blaža $\alpha$** (npr. 0.05 umjesto 0.01) → veća moć

Konvencionalno, istraživači nastoje dizajnirati studije koje imaju moć od najmanje 0.80 (80%). To znači da ako postoji pravi efekt, imamo 80% šanse da ćemo ga detektirati. Prije provedbe studije, možemo koristiti **analizu moći** da odredimo koliki uzorak nam treba za postizanje željene moći:

```{r}
#| label: fig-power-analysis
#| echo: true
#| eval: false

# Funkcija za izračun potrebne veličine uzorka
library(pwr)

# Za t-test s željenom moći od 0.80
# Efekt veličine d = 0.5 (srednji efekt)
# Alpha = 0.05
power_analysis <- pwr.t.test(d = 0.5, 
                              power = 0.80, 
                              sig.level = 0.05,
                              type = "one.sample")

cat("Za postizanje moći od 80% s efektom d = 0.5:\n")
cat("Potreban uzorak:", ceiling(power_analysis$n), "opservacija\n")

# Grafikon moći kao funkcije veličine uzorka
n_values <- seq(10, 200, by = 5)
power_values <- sapply(n_values, function(n) {
  pwr.t.test(d = 0.5, n = n, sig.level = 0.05, 
             type = "one.sample")$power
})

plot(n_values, power_values, type = "l", lwd = 2,
     main = "Moć testa kao funkcija veličine uzorka",
     xlab = "Veličina uzorka (N)",
     ylab = "Moć (1 - β)",
     las = 1)
abline(h = 0.80, lty = 2, col = "red")
abline(v = ceiling(power_analysis$n), lty = 2, col = "blue")
legend("bottomright",
       legend = c("Moć testa", "Željeno: 80%", 
                  sprintf("Potrebno N = %d", ceiling(power_analysis$n))),
       col = c("black", "red", "blue"),
       lwd = c(2, 1, 1),
       lty = c(1, 2, 2))
```

### Tablica odluka {#sec-tablica-odluka}

Možemo sažeti sve moguće ishode testiranja hipoteza u 2×2 tablici:

|  | **$H_0$ je zapravo istinita** | **$H_0$ je zapravo lažna** |
|:---|:---:|:---:|
| **Zadržimo $H_0$** | ✓ Ispravna odluka<br>(Vjerojatnost: $1-\alpha$) | ✗ Pogreška tipa II<br>(Vjerojatnost: $\beta$) |
| **Odbacimo $H_0$** | ✗ Pogreška tipa I<br>(Vjerojatnost: $\alpha$) | ✓ Ispravna odluka<br>(Vjerojatnost: $1-\beta$ = Moć) |

: Ishodi testiranja hipoteza {#tbl-decision-table}

Ova tablica pokazuje fundamentalnu napetost u testiranju hipoteza: ne možemo istovremeno minimizirati obje vrste pogrešaka uz fiksnu veličinu uzorka. Ako smanjimo $\alpha$ (budemo stroži prije odbacivanja $H_0$), automatski povećavamo $\beta$ (postaje nam teže odbaciti lažnu $H_0$). Jedini način da smanjimo obje jest povećati veličinu uzorka.

### Praktične implikacije {#sec-prakticne-implikacije}

Razumijevanje vrsta pogrešaka ima važne praktične implikacije:

**Prvo**, uvijek trebamo izvještavati i o veličini efekta i o p-vrijednosti. P-vrijednost nam govori o statističkoj značajnosti, ali veličina efekta govori o praktičnoj važnosti. Članak s naslovima "Studija otkriva statistički značajan efekt" je beskoristan bez informacije o tome koliko je efekt velik.

**Drugo**, analiza moći treba biti standardni dio planiranja istraživanja. Provoditi studiju koja ima moć od samo 50% (što je začuđujuće često) znači bacati resurse – čak i ako postoji pravi efekt, vjerojatnije je da ga nećemo otkriti nego da hoćemo.

**Treće**, neuspjeh odbacivanja $H_0$ (zadržavanje nulte hipoteze) nije isto što i dokaz da je $H_0$ istinita. Možda efekt postoji, ali smo imali premalo moći da ga detektiramo. Uvijek trebamo razmotriti moć testa prije zaključivanja "nema efekta".

::: {.callout-tip}
## Smjernice za robusno testiranje hipoteza

1. **Planirajte unaprijed**: Odredite $\alpha$ razinu i potrebnu veličinu uzorka prije prikupljanja podataka
2. **Provedite analizu moći**: Osigurajte da vaša studija ima dovoljnu moć (≥ 0.80)
3. **Izvještavajte kompletno**: Uvijek navedite p-vrijednost, veličinu efekta, interval pouzdanosti i veličinu uzorka
4. **Nemojte "loviti" značajnost**: Odluke o analizi trebaju biti planirane unaprijed, ne nakon gledanja podataka
5. **Razlikujte statističku od praktične značajnosti**: Mala p-vrijednost ne znači važan nalaz
:::

## Sažetak {.unnumbered}

U ovom poglavlju razmotrili smo praktične aspekte inferencijalne statistike:

- **Logika nulte hipoteze** – pristup sličan kaznenom suđenju
  - Nulta hipoteza ($H_0$) predstavlja status quo
  - Cilj je pokazati da je $H_0$ (vjerojatno) lažna
  - Presumpcija nevinosti štiti $H_0$ od lažne osude
  - Testna statistika i kritična regija definiraju pravila odlučivanja

- **P-vrijednost** – najmanji $\alpha$ za odbacivanje $H_0$
  - Vjerojatnost podataka (ili ekstremnijih) pod $H_0$
  - **Nije** vjerojatnost da je $H_0$ istinita
  - Konvencije: $p < 0.05$, $p < 0.01$, $p < 0.001$
  - Statistička ≠ praktična značajnost

- **Vrste pogrešaka** – dva načina da pogriješimo
  - Tip I ($\alpha$): odbacivanje istinite $H_0$ (kontroliramo direktno)
  - Tip II ($\beta$): zadržavanje lažne $H_0$ (ovisi o efektu, $N$, varijabilnosti)
  - Moć ($1-\beta$): vjerojatnost detekcije pravog efekta
  - Analiza moći za planiranje veličine uzorka

Ovi koncepti čine okosnicu svih statističkih testova koje ćemo koristiti u analizi komunikoloških podataka.

## Reference {.unnumbered}

::: {#refs}
:::
